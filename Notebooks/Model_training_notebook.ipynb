{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c01ae415-e4bf-4da9-b0cd-87e16b6c2cd5",
   "metadata": {},
   "source": [
    "# Model Training Notebook\n",
    "- In this notebook, we will train an image classifier on the vehicle data we extracted in the previous notebook\n",
    "- We will use Sagemaker's built in image classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d70b201-db7d-4294-a2ad-e0d519835083",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb2d34c-e29e-4c39-acc7-f73e1294dd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker.debugger import Rule, rule_configs\n",
    "from sagemaker.session import TrainingInput\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import IdentitySerializer\n",
    "import base64\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "from sagemaker import image_uris, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa8654a-1b74-48e8-a39c-862ea696095e",
   "metadata": {},
   "source": [
    "## Transform data to correct format for training\n",
    "We need a .lst file (tab separated metadata file) to tell sagemaker, which image to use, where its located and what label it corresponds to. The image classification algorithm expects data in this format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe33eb21-320e-49a3-b599-0e02da2fedb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your custom label mapping\n",
    "vehicle_label_map = {\n",
    "    8: 0,\n",
    "    13: 1,\n",
    "    48: 2,\n",
    "    58: 3,\n",
    "    85: 4,\n",
    "    89: 5\n",
    "}\n",
    "\n",
    "def to_metadata_file(df, prefix):\n",
    "    df[\"s3_path\"] = df[\"filenames\"]\n",
    "\n",
    "    # Apply the label mapping\n",
    "    df[\"labels\"] = df[\"labels\"].apply(lambda x: vehicle_label_map.get(x, -1))\n",
    "\n",
    "    # Save as .lst file for SageMaker\n",
    "    return df[[\"row\", \"labels\", \"s3_path\"]].to_csv(\n",
    "        f\"{prefix}.lst\", sep=\"\\t\", index=False, header=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a120284-4d9d-4691-b072-35b75dcaab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../Data/df_train.csv\")\n",
    "df_test = pd.read_csv(\"../Data/df_test.csv\")\n",
    "\n",
    "to_metadata_file(df_train.copy(), \"../Data/train\")\n",
    "to_metadata_file(df_test.copy(), \"../Data/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "040b35bb-4910-4f6d-ad91-4af26e24d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"sagemaker-us-east-1-351669278598\"\n",
    "region='us-east-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df4adf6a-da9a-4f7f-93dd-133843ad14cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload files\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(\n",
    "    bucket).Object('vehicle_data/train.lst').upload_file('../Data/train.lst')\n",
    "boto3.Session().resource('s3').Bucket(\n",
    "    bucket).Object('vehicle_data/test.lst').upload_file('../Data/test.lst')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313f0743-15ec-46bf-9a96-c36759d61ced",
   "metadata": {},
   "source": [
    "## Configure Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de5ccf72-cf79-4053-a3ad-2cb0cfacf6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/07/25 15:46:08] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Same images used for training and inference. Defaulting to image     <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py#393\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">393</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         scope: inference.                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/07/25 15:46:08]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Same images used for training and inference. Defaulting to image     \u001b]8;id=317052;file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=482522;file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py#393\u001b\\\u001b[2m393\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         scope: inference.                                                    \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/07/25 15:46:09] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Ignoring unnecessary instance type: <span style=\"color: #e100e1; text-decoration-color: #e100e1; font-style: italic\">None</span>.                            <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py#530\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">530</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/07/25 15:46:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Ignoring unnecessary instance type: \u001b[3;38;2;225;0;225mNone\u001b[0m.                            \u001b]8;id=780414;file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=877104;file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py#530\u001b\\\u001b[2m530\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the image_uris function to retrieve the latest 'image-classification' image \n",
    "algo_image = image_uris.retrieve(\n",
    "    region=region,\n",
    "    framework='image-classification',\n",
    "    version='latest'\n",
    ")\n",
    "s3_output_location = f\"s3://{bucket}/models/image_model\" # this is where model artifacts are saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a24b1064-dcf9-4e66-a1e8-60582a3f585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "\n",
    "img_classifier_model=sagemaker.estimator.Estimator(\n",
    "    image_uri=algo_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    volume_size=5,\n",
    "    output_path=s3_output_location,\n",
    "    sagemaker_session=sagemaker.Session()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cbe72400-d938-4f08-adce-982b79028bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_classifier_model.set_hyperparameters(\n",
    "    image_shape= \"3,32,32\",\n",
    "    num_classes= 6,\n",
    "    num_training_samples= len(df_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29eb3a75-23e7-49a3-a25a-7a732826cfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = {\n",
    "        \"train\": sagemaker.inputs.TrainingInput(\n",
    "            s3_data=f\"s3://{bucket}/vehicle_data/train/\",\n",
    "            content_type=\"application/x-image\"\n",
    "        ),\n",
    "        \"validation\": sagemaker.inputs.TrainingInput(\n",
    "            s3_data=f\"s3://{bucket}/vehicle_data/test/\",\n",
    "            content_type=\"application/x-image\"\n",
    "        ),\n",
    "        \"train_lst\": sagemaker.inputs.TrainingInput(\n",
    "            s3_data=f\"s3://{bucket}/vehicle_data/train.lst\",\n",
    "            content_type=\"application/x-image\"\n",
    "        ),\n",
    "        \"validation_lst\": sagemaker.inputs.TrainingInput(\n",
    "            s3_data=f\"s3://{bucket}/vehicle_data/test.lst\",\n",
    "            content_type=\"application/x-image\"\n",
    "        )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6c02644-f4e6-4000-ad4e-95ba62ff5b10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/07/25 15:46:13] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/07/25 15:46:13]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=203017;file:///opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=108524;file:///opt/conda/lib/python3.11/site-packages/sagemaker/telemetry/telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name:                                       <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         image-classification-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-04-07-15-46-13-797                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name:                                       \u001b]8;id=961719;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=671551;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         image-classification-\u001b[1;36m2025\u001b[0m-04-07-15-46-13-797                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-07 15:46:14 Starting - Starting the training job\n",
      "...........15:46:14 Pending - Training job waiting for capacity.\n",
      "..25-04-07 15:47:53 Pending - Preparing the instances for training.\n",
      "..25-04-07 15:48:24 Downloading - Downloading input data.\n",
      "..............48:55 Downloading - Downloading the training image.\n",
      "\u001b[34mDocker entrypoint called with argument(s): train\u001b[0mmpleted. Training in progress..\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34mNvidia gpu devices, drivers and cuda toolkit versions (only available on hosts with GPU):\u001b[0m\n",
      "\u001b[34mMon Apr  7 15:51:51 2025       \u001b[0m\n",
      "\u001b[34m+-----------------------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[34m| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |\u001b[0m\n",
      "\u001b[34m|-----------------------------------------+------------------------+----------------------+\u001b[0m\n",
      "\u001b[34m| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\u001b[0m\n",
      "\u001b[34m| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\u001b[0m\n",
      "\u001b[34m|                                         |                        |               MIG M. |\u001b[0m\n",
      "\u001b[34m|=========================================+========================+======================|\u001b[0m\n",
      "\u001b[34m|   0  Tesla V100-SXM2-16GB           On  |   00000000:00:1E.0 Off |                    0 |\u001b[0m\n",
      "\u001b[34m| N/A   31C    P0             23W /  300W |       1MiB /  16384MiB |      0%      Default |\u001b[0m\n",
      "\u001b[34m|                                         |                        |                  N/A |\u001b[0m\n",
      "\u001b[34m+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \u001b[0m\n",
      "\u001b[34m+-----------------------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[34m| Processes:                                                                              |\u001b[0m\n",
      "\u001b[34m|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\u001b[0m\n",
      "\u001b[34m|        ID   ID                                                               Usage      |\u001b[0m\n",
      "\u001b[34m|=========================================================================================|\u001b[0m\n",
      "\u001b[34m|  No running processes found                                                             |\u001b[0m\n",
      "\u001b[34m+-----------------------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[34mChecking for nvidia driver and cuda compatibility.\u001b[0m\n",
      "\u001b[34mCUDA Compatibility driver provided.\u001b[0m\n",
      "\u001b[34mProceeding with compatibility check between driver, cuda-toolkit and cuda-compat.\u001b[0m\n",
      "\u001b[34mDetected cuda-toolkit version: 11.1.\u001b[0m\n",
      "\u001b[34mDetected cuda-compat version: 455.32.00.\u001b[0m\n",
      "\u001b[34mDetected Nvidia driver version: 550.144.03.\u001b[0m\n",
      "\u001b[34mNvidia driver compatible with cuda-toolkit. Disabling cuda-compat.\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:55 INFO 140486410860352] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/image_classification/default-input.json: {'use_pretrained_model': 0, 'num_layers': 152, 'epochs': 30, 'learning_rate': 0.1, 'lr_scheduler_factor': 0.1, 'optimizer': 'sgd', 'momentum': 0, 'weight_decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'eps': 1e-08, 'gamma': 0.9, 'mini_batch_size': 32, 'image_shape': '3,224,224', 'precision_dtype': 'float32'}\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:55 INFO 140486410860352] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'image_shape': '3,32,32', 'num_classes': '6', 'num_training_samples': '3000'}\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:55 INFO 140486410860352] Final configuration: {'use_pretrained_model': 0, 'num_layers': 152, 'epochs': 30, 'learning_rate': 0.1, 'lr_scheduler_factor': 0.1, 'optimizer': 'sgd', 'momentum': 0, 'weight_decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'eps': 1e-08, 'gamma': 0.9, 'mini_batch_size': 32, 'image_shape': '3,32,32', 'precision_dtype': 'float32', 'num_classes': '6', 'num_training_samples': '3000'}\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:55 INFO 140486410860352] Searching for .lst files in /opt/ml/input/data/train_lst.\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:55 INFO 140486410860352] Creating record files for train.lst\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:55 INFO 140486410860352] Done creating record files...\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:55 INFO 140486410860352] Searching for .lst files in /opt/ml/input/data/validation_lst.\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:55 INFO 140486410860352] Creating record files for test.lst\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:56 INFO 140486410860352] Done creating record files...\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:56 INFO 140486410860352] use_pretrained_model: 0\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:56 INFO 140486410860352] multi_label: 0\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:56 INFO 140486410860352] Performing random weight initialization\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:56 INFO 140486410860352] ---- Parameters ----\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:56 INFO 140486410860352] num_layers: 152\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:56 INFO 140486410860352] data type: <class 'numpy.float32'>\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:56 INFO 140486410860352] epochs: 30\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:56 INFO 140486410860352] optimizer: sgd\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:56 INFO 140486410860352] momentum: 0.9\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:56 INFO 140486410860352] weight_decay: 0.0001\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:56 INFO 140486410860352] learning_rate: 0.1\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:56 INFO 140486410860352] num_training_samples: 3000\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:56 INFO 140486410860352] mini_batch_size: 32\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:56 INFO 140486410860352] image_shape: 3,32,32\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:56 INFO 140486410860352] num_classes: 6\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:56 INFO 140486410860352] augmentation_type: None\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:56 INFO 140486410860352] kv_store: device\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:56 INFO 140486410860352] checkpoint_frequency not set, will store the best model\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:56 INFO 140486410860352] --------------------\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:51:56 INFO 140486410860352] Setting number of threads: 7\u001b[0m\n",
      "\u001b[34m[15:52:00] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_11.1.x.441.0/AL2_x86_64/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:05 INFO 140486410860352] Epoch[0] Batch [20]#011Speed: 122.708 samples/sec#011accuracy=0.177083\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:08 INFO 140486410860352] Epoch[0] Batch [40]#011Speed: 151.436 samples/sec#011accuracy=0.174543\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:11 INFO 140486410860352] Epoch[0] Batch [60]#011Speed: 164.466 samples/sec#011accuracy=0.182889\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:15 INFO 140486410860352] Epoch[0] Batch [80]#011Speed: 171.749 samples/sec#011accuracy=0.186343\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:17 INFO 140486410860352] Epoch[0] Train-accuracy=0.191532\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:17 INFO 140486410860352] Epoch[0] Time cost=16.860\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:18 INFO 140486410860352] Epoch[0] Validation-accuracy=0.225329\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:18 INFO 140486410860352] Storing the best model with validation accuracy: 0.225329\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:18 INFO 140486410860352] Saved checkpoint to \"/opt/ml/model/image-classification-0001.params\"\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:22 INFO 140486410860352] Epoch[1] Batch [20]#011Speed: 188.788 samples/sec#011accuracy=0.235119\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:25 INFO 140486410860352] Epoch[1] Batch [40]#011Speed: 193.770 samples/sec#011accuracy=0.261433\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:28 INFO 140486410860352] Epoch[1] Batch [60]#011Speed: 195.436 samples/sec#011accuracy=0.278689\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:31 INFO 140486410860352] Epoch[1] Batch [80]#011Speed: 196.528 samples/sec#011accuracy=0.298225\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:33 INFO 140486410860352] Epoch[1] Train-accuracy=0.312836\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:33 INFO 140486410860352] Epoch[1] Time cost=14.960\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:35 INFO 140486410860352] Epoch[1] Validation-accuracy=0.365132\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:35 INFO 140486410860352] Storing the best model with validation accuracy: 0.365132\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:35 INFO 140486410860352] Saved checkpoint to \"/opt/ml/model/image-classification-0002.params\"\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:39 INFO 140486410860352] Epoch[2] Batch [20]#011Speed: 196.846 samples/sec#011accuracy=0.391369\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:42 INFO 140486410860352] Epoch[2] Batch [40]#011Speed: 198.141 samples/sec#011accuracy=0.411585\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:45 INFO 140486410860352] Epoch[2] Batch [60]#011Speed: 198.689 samples/sec#011accuracy=0.402664\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:48 INFO 140486410860352] Epoch[2] Batch [80]#011Speed: 198.851 samples/sec#011accuracy=0.406636\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:50 INFO 140486410860352] Epoch[2] Train-accuracy=0.407594\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:50 INFO 140486410860352] Epoch[2] Time cost=14.804\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:51 INFO 140486410860352] Epoch[2] Validation-accuracy=0.442434\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:52 INFO 140486410860352] Storing the best model with validation accuracy: 0.442434\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:52 INFO 140486410860352] Saved checkpoint to \"/opt/ml/model/image-classification-0003.params\"\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:55 INFO 140486410860352] Epoch[3] Batch [20]#011Speed: 196.497 samples/sec#011accuracy=0.443452\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:52:58 INFO 140486410860352] Epoch[3] Batch [40]#011Speed: 197.694 samples/sec#011accuracy=0.451982\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:02 INFO 140486410860352] Epoch[3] Batch [60]#011Speed: 197.794 samples/sec#011accuracy=0.456967\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:05 INFO 140486410860352] Epoch[3] Batch [80]#011Speed: 197.943 samples/sec#011accuracy=0.457176\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:07 INFO 140486410860352] Epoch[3] Train-accuracy=0.459341\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:07 INFO 140486410860352] Epoch[3] Time cost=14.843\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:08 INFO 140486410860352] Epoch[3] Validation-accuracy=0.460069\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:08 INFO 140486410860352] Storing the best model with validation accuracy: 0.460069\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:09 INFO 140486410860352] Saved checkpoint to \"/opt/ml/model/image-classification-0004.params\"\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:12 INFO 140486410860352] Epoch[4] Batch [20]#011Speed: 191.568 samples/sec#011accuracy=0.495536\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:15 INFO 140486410860352] Epoch[4] Batch [40]#011Speed: 195.612 samples/sec#011accuracy=0.510671\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:18 INFO 140486410860352] Epoch[4] Batch [60]#011Speed: 197.342 samples/sec#011accuracy=0.522029\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:22 INFO 140486410860352] Epoch[4] Batch [80]#011Speed: 197.571 samples/sec#011accuracy=0.525077\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:24 INFO 140486410860352] Epoch[4] Train-accuracy=0.528226\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:24 INFO 140486410860352] Epoch[4] Time cost=14.867\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:25 INFO 140486410860352] Epoch[4] Validation-accuracy=0.457237\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:29 INFO 140486410860352] Epoch[5] Batch [20]#011Speed: 194.439 samples/sec#011accuracy=0.565476\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:32 INFO 140486410860352] Epoch[5] Batch [40]#011Speed: 196.835 samples/sec#011accuracy=0.552591\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:35 INFO 140486410860352] Epoch[5] Batch [60]#011Speed: 197.513 samples/sec#011accuracy=0.545082\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:38 INFO 140486410860352] Epoch[5] Batch [80]#011Speed: 197.704 samples/sec#011accuracy=0.555556\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:40 INFO 140486410860352] Epoch[5] Train-accuracy=0.559140\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:40 INFO 140486410860352] Epoch[5] Time cost=14.866\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:41 INFO 140486410860352] Epoch[5] Validation-accuracy=0.554276\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:42 INFO 140486410860352] Storing the best model with validation accuracy: 0.554276\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:42 INFO 140486410860352] Saved checkpoint to \"/opt/ml/model/image-classification-0006.params\"\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:45 INFO 140486410860352] Epoch[6] Batch [20]#011Speed: 195.651 samples/sec#011accuracy=0.589286\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:48 INFO 140486410860352] Epoch[6] Batch [40]#011Speed: 197.465 samples/sec#011accuracy=0.602896\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:52 INFO 140486410860352] Epoch[6] Batch [60]#011Speed: 198.159 samples/sec#011accuracy=0.612705\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:55 INFO 140486410860352] Epoch[6] Batch [80]#011Speed: 198.414 samples/sec#011accuracy=0.608410\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:57 INFO 140486410860352] Epoch[6] Train-accuracy=0.610215\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:57 INFO 140486410860352] Epoch[6] Time cost=14.832\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:53:58 INFO 140486410860352] Epoch[6] Validation-accuracy=0.547697\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:02 INFO 140486410860352] Epoch[7] Batch [20]#011Speed: 194.193 samples/sec#011accuracy=0.650298\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:05 INFO 140486410860352] Epoch[7] Batch [40]#011Speed: 197.418 samples/sec#011accuracy=0.643293\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:08 INFO 140486410860352] Epoch[7] Batch [60]#011Speed: 197.923 samples/sec#011accuracy=0.647541\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:11 INFO 140486410860352] Epoch[7] Batch [80]#011Speed: 198.300 samples/sec#011accuracy=0.654321\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:13 INFO 140486410860352] Epoch[7] Train-accuracy=0.650538\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:13 INFO 140486410860352] Epoch[7] Time cost=14.841\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:14 INFO 140486410860352] Epoch[7] Validation-accuracy=0.581597\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:15 INFO 140486410860352] Storing the best model with validation accuracy: 0.581597\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:15 INFO 140486410860352] Saved checkpoint to \"/opt/ml/model/image-classification-0008.params\"\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:19 INFO 140486410860352] Epoch[8] Batch [20]#011Speed: 192.252 samples/sec#011accuracy=0.726190\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:22 INFO 140486410860352] Epoch[8] Batch [40]#011Speed: 196.744 samples/sec#011accuracy=0.710366\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:25 INFO 140486410860352] Epoch[8] Batch [60]#011Speed: 198.093 samples/sec#011accuracy=0.701332\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:28 INFO 140486410860352] Epoch[8] Batch [80]#011Speed: 198.664 samples/sec#011accuracy=0.700231\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:30 INFO 140486410860352] Epoch[8] Train-accuracy=0.693548\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:30 INFO 140486410860352] Epoch[8] Time cost=14.802\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:31 INFO 140486410860352] Epoch[8] Validation-accuracy=0.537829\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:35 INFO 140486410860352] Epoch[9] Batch [20]#011Speed: 196.772 samples/sec#011accuracy=0.784226\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:38 INFO 140486410860352] Epoch[9] Batch [40]#011Speed: 199.315 samples/sec#011accuracy=0.753049\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:41 INFO 140486410860352] Epoch[9] Batch [60]#011Speed: 200.080 samples/sec#011accuracy=0.744365\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:45 INFO 140486410860352] Epoch[9] Batch [80]#011Speed: 199.557 samples/sec#011accuracy=0.746528\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:46 INFO 140486410860352] Epoch[9] Train-accuracy=0.745632\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:46 INFO 140486410860352] Epoch[9] Time cost=14.748\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:48 INFO 140486410860352] Epoch[9] Validation-accuracy=0.611842\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:48 INFO 140486410860352] Storing the best model with validation accuracy: 0.611842\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:48 INFO 140486410860352] Saved checkpoint to \"/opt/ml/model/image-classification-0010.params\"\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:52 INFO 140486410860352] Epoch[10] Batch [20]#011Speed: 195.912 samples/sec#011accuracy=0.825893\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:55 INFO 140486410860352] Epoch[10] Batch [40]#011Speed: 197.649 samples/sec#011accuracy=0.803354\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:54:58 INFO 140486410860352] Epoch[10] Batch [60]#011Speed: 198.478 samples/sec#011accuracy=0.782787\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:01 INFO 140486410860352] Epoch[10] Batch [80]#011Speed: 198.587 samples/sec#011accuracy=0.778549\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:03 INFO 140486410860352] Epoch[10] Train-accuracy=0.779570\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:03 INFO 140486410860352] Epoch[10] Time cost=14.820\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:04 INFO 140486410860352] Epoch[10] Validation-accuracy=0.603618\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:08 INFO 140486410860352] Epoch[11] Batch [20]#011Speed: 195.390 samples/sec#011accuracy=0.851190\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:11 INFO 140486410860352] Epoch[11] Batch [40]#011Speed: 197.718 samples/sec#011accuracy=0.828506\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:15 INFO 140486410860352] Epoch[11] Batch [60]#011Speed: 198.289 samples/sec#011accuracy=0.826332\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:18 INFO 140486410860352] Epoch[11] Batch [80]#011Speed: 198.668 samples/sec#011accuracy=0.812886\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:20 INFO 140486410860352] Epoch[11] Train-accuracy=0.798723\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:20 INFO 140486410860352] Epoch[11] Time cost=14.817\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:21 INFO 140486410860352] Epoch[11] Validation-accuracy=0.588542\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:25 INFO 140486410860352] Epoch[12] Batch [20]#011Speed: 193.477 samples/sec#011accuracy=0.873512\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:28 INFO 140486410860352] Epoch[12] Batch [40]#011Speed: 196.451 samples/sec#011accuracy=0.883384\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:31 INFO 140486410860352] Epoch[12] Batch [60]#011Speed: 197.830 samples/sec#011accuracy=0.870389\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:34 INFO 140486410860352] Epoch[12] Batch [80]#011Speed: 198.176 samples/sec#011accuracy=0.854167\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:36 INFO 140486410860352] Epoch[12] Train-accuracy=0.843750\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:36 INFO 140486410860352] Epoch[12] Time cost=14.843\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:37 INFO 140486410860352] Epoch[12] Validation-accuracy=0.613487\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:38 INFO 140486410860352] Storing the best model with validation accuracy: 0.613487\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:38 INFO 140486410860352] Saved checkpoint to \"/opt/ml/model/image-classification-0013.params\"\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:41 INFO 140486410860352] Epoch[13] Batch [20]#011Speed: 194.924 samples/sec#011accuracy=0.872024\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:45 INFO 140486410860352] Epoch[13] Batch [40]#011Speed: 197.708 samples/sec#011accuracy=0.882622\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:48 INFO 140486410860352] Epoch[13] Batch [60]#011Speed: 198.204 samples/sec#011accuracy=0.885246\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:51 INFO 140486410860352] Epoch[13] Batch [80]#011Speed: 198.422 samples/sec#011accuracy=0.877315\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:53 INFO 140486410860352] Epoch[13] Train-accuracy=0.878360\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:53 INFO 140486410860352] Epoch[13] Time cost=14.822\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:54 INFO 140486410860352] Epoch[13] Validation-accuracy=0.611842\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:55:58 INFO 140486410860352] Epoch[14] Batch [20]#011Speed: 196.747 samples/sec#011accuracy=0.943452\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:01 INFO 140486410860352] Epoch[14] Batch [40]#011Speed: 198.617 samples/sec#011accuracy=0.942073\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:04 INFO 140486410860352] Epoch[14] Batch [60]#011Speed: 199.133 samples/sec#011accuracy=0.923156\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:07 INFO 140486410860352] Epoch[14] Batch [80]#011Speed: 199.249 samples/sec#011accuracy=0.916281\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:09 INFO 140486410860352] Epoch[14] Train-accuracy=0.909274\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:09 INFO 140486410860352] Epoch[14] Time cost=14.758\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:11 INFO 140486410860352] Epoch[14] Validation-accuracy=0.598684\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:14 INFO 140486410860352] Epoch[15] Batch [20]#011Speed: 195.204 samples/sec#011accuracy=0.924107\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:18 INFO 140486410860352] Epoch[15] Batch [40]#011Speed: 198.269 samples/sec#011accuracy=0.932165\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:21 INFO 140486410860352] Epoch[15] Batch [60]#011Speed: 198.972 samples/sec#011accuracy=0.925205\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:24 INFO 140486410860352] Epoch[15] Batch [80]#011Speed: 199.222 samples/sec#011accuracy=0.921682\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:26 INFO 140486410860352] Epoch[15] Train-accuracy=0.917675\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:26 INFO 140486410860352] Epoch[15] Time cost=14.768\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:27 INFO 140486410860352] Epoch[15] Validation-accuracy=0.607639\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:31 INFO 140486410860352] Epoch[16] Batch [20]#011Speed: 194.418 samples/sec#011accuracy=0.900298\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:34 INFO 140486410860352] Epoch[16] Batch [40]#011Speed: 197.202 samples/sec#011accuracy=0.916159\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:37 INFO 140486410860352] Epoch[16] Batch [60]#011Speed: 198.139 samples/sec#011accuracy=0.921107\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:40 INFO 140486410860352] Epoch[16] Batch [80]#011Speed: 198.964 samples/sec#011accuracy=0.915895\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:42 INFO 140486410860352] Epoch[16] Train-accuracy=0.909946\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:42 INFO 140486410860352] Epoch[16] Time cost=14.775\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:43 INFO 140486410860352] Epoch[16] Validation-accuracy=0.605263\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:47 INFO 140486410860352] Epoch[17] Batch [20]#011Speed: 194.093 samples/sec#011accuracy=0.930060\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:50 INFO 140486410860352] Epoch[17] Batch [40]#011Speed: 197.909 samples/sec#011accuracy=0.942835\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:54 INFO 140486410860352] Epoch[17] Batch [60]#011Speed: 198.457 samples/sec#011accuracy=0.936475\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:57 INFO 140486410860352] Epoch[17] Batch [80]#011Speed: 199.041 samples/sec#011accuracy=0.932485\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:59 INFO 140486410860352] Epoch[17] Train-accuracy=0.930780\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:56:59 INFO 140486410860352] Epoch[17] Time cost=14.771\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:00 INFO 140486410860352] Epoch[17] Validation-accuracy=0.577303\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:04 INFO 140486410860352] Epoch[18] Batch [20]#011Speed: 195.987 samples/sec#011accuracy=0.940476\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:07 INFO 140486410860352] Epoch[18] Batch [40]#011Speed: 198.076 samples/sec#011accuracy=0.956555\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:10 INFO 140486410860352] Epoch[18] Batch [60]#011Speed: 198.870 samples/sec#011accuracy=0.955430\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:13 INFO 140486410860352] Epoch[18] Batch [80]#011Speed: 199.145 samples/sec#011accuracy=0.952932\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:15 INFO 140486410860352] Epoch[18] Train-accuracy=0.953293\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:15 INFO 140486410860352] Epoch[18] Time cost=14.785\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:16 INFO 140486410860352] Epoch[18] Validation-accuracy=0.559211\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:20 INFO 140486410860352] Epoch[19] Batch [20]#011Speed: 197.629 samples/sec#011accuracy=0.943452\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:23 INFO 140486410860352] Epoch[19] Batch [40]#011Speed: 199.301 samples/sec#011accuracy=0.955030\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:26 INFO 140486410860352] Epoch[19] Batch [60]#011Speed: 199.383 samples/sec#011accuracy=0.961578\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:30 INFO 140486410860352] Epoch[19] Batch [80]#011Speed: 199.552 samples/sec#011accuracy=0.959877\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:32 INFO 140486410860352] Epoch[19] Train-accuracy=0.958333\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:32 INFO 140486410860352] Epoch[19] Time cost=14.729\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:33 INFO 140486410860352] Epoch[19] Validation-accuracy=0.553819\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:36 INFO 140486410860352] Epoch[20] Batch [20]#011Speed: 194.180 samples/sec#011accuracy=0.955357\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:40 INFO 140486410860352] Epoch[20] Batch [40]#011Speed: 197.062 samples/sec#011accuracy=0.957317\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:43 INFO 140486410860352] Epoch[20] Batch [60]#011Speed: 198.130 samples/sec#011accuracy=0.960041\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:46 INFO 140486410860352] Epoch[20] Batch [80]#011Speed: 198.678 samples/sec#011accuracy=0.960648\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:48 INFO 140486410860352] Epoch[20] Train-accuracy=0.961022\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:48 INFO 140486410860352] Epoch[20] Time cost=14.808\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:49 INFO 140486410860352] Epoch[20] Validation-accuracy=0.605263\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:53 INFO 140486410860352] Epoch[21] Batch [20]#011Speed: 196.572 samples/sec#011accuracy=0.974702\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:56 INFO 140486410860352] Epoch[21] Batch [40]#011Speed: 198.382 samples/sec#011accuracy=0.976372\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:57:59 INFO 140486410860352] Epoch[21] Batch [60]#011Speed: 199.008 samples/sec#011accuracy=0.973873\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:03 INFO 140486410860352] Epoch[21] Batch [80]#011Speed: 198.694 samples/sec#011accuracy=0.971836\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:04 INFO 140486410860352] Epoch[21] Train-accuracy=0.971102\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:04 INFO 140486410860352] Epoch[21] Time cost=14.797\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:06 INFO 140486410860352] Epoch[21] Validation-accuracy=0.606908\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:09 INFO 140486410860352] Epoch[22] Batch [20]#011Speed: 197.606 samples/sec#011accuracy=0.974702\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:13 INFO 140486410860352] Epoch[22] Batch [40]#011Speed: 199.477 samples/sec#011accuracy=0.973323\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:16 INFO 140486410860352] Epoch[22] Batch [60]#011Speed: 200.226 samples/sec#011accuracy=0.966701\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:19 INFO 140486410860352] Epoch[22] Batch [80]#011Speed: 199.679 samples/sec#011accuracy=0.960648\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:21 INFO 140486410860352] Epoch[22] Train-accuracy=0.958333\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:21 INFO 140486410860352] Epoch[22] Time cost=14.725\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:22 INFO 140486410860352] Epoch[22] Validation-accuracy=0.605263\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:26 INFO 140486410860352] Epoch[23] Batch [20]#011Speed: 198.353 samples/sec#011accuracy=0.979167\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:29 INFO 140486410860352] Epoch[23] Batch [40]#011Speed: 199.719 samples/sec#011accuracy=0.978659\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:32 INFO 140486410860352] Epoch[23] Batch [60]#011Speed: 200.009 samples/sec#011accuracy=0.977971\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:35 INFO 140486410860352] Epoch[23] Batch [80]#011Speed: 200.213 samples/sec#011accuracy=0.977623\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:37 INFO 140486410860352] Epoch[23] Train-accuracy=0.976142\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:37 INFO 140486410860352] Epoch[23] Time cost=14.692\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:38 INFO 140486410860352] Epoch[23] Validation-accuracy=0.583333\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:42 INFO 140486410860352] Epoch[24] Batch [20]#011Speed: 193.710 samples/sec#011accuracy=0.971726\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:45 INFO 140486410860352] Epoch[24] Batch [40]#011Speed: 197.268 samples/sec#011accuracy=0.967988\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:49 INFO 140486410860352] Epoch[24] Batch [60]#011Speed: 198.022 samples/sec#011accuracy=0.963627\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:52 INFO 140486410860352] Epoch[24] Batch [80]#011Speed: 198.595 samples/sec#011accuracy=0.964892\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:54 INFO 140486410860352] Epoch[24] Train-accuracy=0.966398\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:54 INFO 140486410860352] Epoch[24] Time cost=14.795\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:55 INFO 140486410860352] Epoch[24] Validation-accuracy=0.644737\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:55 INFO 140486410860352] Storing the best model with validation accuracy: 0.644737\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:56 INFO 140486410860352] Saved checkpoint to \"/opt/ml/model/image-classification-0025.params\"\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:58:59 INFO 140486410860352] Epoch[25] Batch [20]#011Speed: 197.083 samples/sec#011accuracy=0.973214\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:02 INFO 140486410860352] Epoch[25] Batch [40]#011Speed: 198.570 samples/sec#011accuracy=0.972561\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:05 INFO 140486410860352] Epoch[25] Batch [60]#011Speed: 199.184 samples/sec#011accuracy=0.974898\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:08 INFO 140486410860352] Epoch[25] Batch [80]#011Speed: 199.338 samples/sec#011accuracy=0.974537\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:10 INFO 140486410860352] Epoch[25] Train-accuracy=0.972446\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:10 INFO 140486410860352] Epoch[25] Time cost=14.753\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:12 INFO 140486410860352] Epoch[25] Validation-accuracy=0.587171\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:15 INFO 140486410860352] Epoch[26] Batch [20]#011Speed: 195.285 samples/sec#011accuracy=0.970238\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:18 INFO 140486410860352] Epoch[26] Batch [40]#011Speed: 197.685 samples/sec#011accuracy=0.954268\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:22 INFO 140486410860352] Epoch[26] Batch [60]#011Speed: 198.842 samples/sec#011accuracy=0.952869\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:25 INFO 140486410860352] Epoch[26] Batch [80]#011Speed: 198.542 samples/sec#011accuracy=0.955633\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:27 INFO 140486410860352] Epoch[26] Train-accuracy=0.956317\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:27 INFO 140486410860352] Epoch[26] Time cost=14.822\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:28 INFO 140486410860352] Epoch[26] Validation-accuracy=0.605263\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:32 INFO 140486410860352] Epoch[27] Batch [20]#011Speed: 197.101 samples/sec#011accuracy=0.980655\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:35 INFO 140486410860352] Epoch[27] Batch [40]#011Speed: 199.441 samples/sec#011accuracy=0.985518\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:38 INFO 140486410860352] Epoch[27] Batch [60]#011Speed: 199.551 samples/sec#011accuracy=0.986680\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:41 INFO 140486410860352] Epoch[27] Batch [80]#011Speed: 199.865 samples/sec#011accuracy=0.984182\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:43 INFO 140486410860352] Epoch[27] Train-accuracy=0.981855\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:43 INFO 140486410860352] Epoch[27] Time cost=14.727\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:45 INFO 140486410860352] Epoch[27] Validation-accuracy=0.616319\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:48 INFO 140486410860352] Epoch[28] Batch [20]#011Speed: 194.790 samples/sec#011accuracy=0.977679\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:52 INFO 140486410860352] Epoch[28] Batch [40]#011Speed: 197.454 samples/sec#011accuracy=0.981707\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:55 INFO 140486410860352] Epoch[28] Batch [60]#011Speed: 198.346 samples/sec#011accuracy=0.984119\u001b[0m\n",
      "\u001b[34m[04/07/2025 15:59:58 INFO 140486410860352] Epoch[28] Batch [80]#011Speed: 199.081 samples/sec#011accuracy=0.985725\u001b[0m\n",
      "\u001b[34m[04/07/2025 16:00:00 INFO 140486410860352] Epoch[28] Train-accuracy=0.985887\u001b[0m\n",
      "\u001b[34m[04/07/2025 16:00:00 INFO 140486410860352] Epoch[28] Time cost=14.782\u001b[0m\n",
      "\u001b[34m[04/07/2025 16:00:01 INFO 140486410860352] Epoch[28] Validation-accuracy=0.618421\u001b[0m\n",
      "\u001b[34m[04/07/2025 16:00:05 INFO 140486410860352] Epoch[29] Batch [20]#011Speed: 196.906 samples/sec#011accuracy=0.986607\u001b[0m\n",
      "\u001b[34m[04/07/2025 16:00:08 INFO 140486410860352] Epoch[29] Batch [40]#011Speed: 198.189 samples/sec#011accuracy=0.984756\u001b[0m\n",
      "\u001b[34m[04/07/2025 16:00:11 INFO 140486410860352] Epoch[29] Batch [60]#011Speed: 198.999 samples/sec#011accuracy=0.985143\u001b[0m\n",
      "\u001b[34m[04/07/2025 16:00:14 INFO 140486410860352] Epoch[29] Batch [80]#011Speed: 199.524 samples/sec#011accuracy=0.987269\u001b[0m\n",
      "\n",
      "2025-04-07 16:00:23 Uploading - Uploading generated training model\u001b[34m[04/07/2025 16:00:16 INFO 140486410860352] Epoch[29] Train-accuracy=0.986559\u001b[0m\n",
      "\u001b[34m[04/07/2025 16:00:16 INFO 140486410860352] Epoch[29] Time cost=14.750\u001b[0m\n",
      "\u001b[34m[04/07/2025 16:00:18 INFO 140486410860352] Epoch[29] Validation-accuracy=0.611842\u001b[0m\n",
      "\n",
      "2025-04-07 16:00:42 Completed - Training job completed\n",
      "Training seconds: 737\n",
      "Billable seconds: 737\n"
     ]
    }
   ],
   "source": [
    "img_classifier_model.fit(model_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46353d05-7cc5-4a5c-88a7-4c82074efa4a",
   "metadata": {},
   "source": [
    "## Deploy model/ Can redploy model without retraining\n",
    "- dont forget to delete endpoint if not using\n",
    "- if redeploying, edit the endpoint address in the lambda classify function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3dea62a-29a0-40c9-98b5-34dc12b9fbcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/10/25 15:21:13] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Same images used for training and inference. Defaulting to image     <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py#393\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">393</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         scope: inference.                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/10/25 15:21:13]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Same images used for training and inference. Defaulting to image     \u001b]8;id=733059;file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=600302;file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py#393\u001b\\\u001b[2m393\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         scope: inference.                                                    \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Ignoring unnecessary instance type: <span style=\"color: #e100e1; text-decoration-color: #e100e1; font-style: italic\">None</span>.                            <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py#530\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">530</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Ignoring unnecessary instance type: \u001b[3;38;2;225;0;225mNone\u001b[0m.                            \u001b]8;id=371076;file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=227776;file:///opt/conda/lib/python3.11/site-packages/sagemaker/image_uris.py#530\u001b\\\u001b[2m530\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bucket = 'sagemaker-us-east-1-351669278598'\n",
    "role = get_execution_role()\n",
    "region = 'us-east-1'\n",
    "\n",
    "# find model tar file in s3 bucket of previously trained model\n",
    "model_path = 's3://sagemaker-us-east-1-351669278598/models/image_model/image-classification-2025-04-07-15-46-13-797/output/model.tar.gz'\n",
    "\n",
    "# Image URI for SageMaker's image classification algorithm\n",
    "algo_image = image_uris.retrieve(\n",
    "    region=region,\n",
    "    framework='image-classification',\n",
    "    version='latest'\n",
    ")\n",
    "\n",
    "# Create the Model object\n",
    "img_classifier_model = Model(\n",
    "    image_uri=algo_image,\n",
    "    model_data=model_path,\n",
    "    role=role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8633f83-306e-46c7-8fc5-842918d5c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_uri = f's3://{bucket}/data-capture'\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    sampling_percentage=100,\n",
    "    destination_s3_uri=capture_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "264a6ca8-5a6f-463c-9187-f43e5fa92281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-351669278598/data-capture'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capture_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fbcf0df-5d6f-45b8-9d47-abdecde81930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/10/25 15:21:27] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: image-classification-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-04-10-15-21-27-013 <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/10/25 15:21:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: image-classification-\u001b[1;36m2025\u001b[0m-04-10-15-21-27-013 \u001b]8;id=106585;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=72697;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name vehicle-detector-endpoint-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>  <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#5889\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5889</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name vehicle-detector-endpoint-\u001b[1;36m10\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m25\u001b[0m  \u001b]8;id=593698;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=41656;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#5889\u001b\\\u001b[2m5889\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/10/25 15:21:28] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name vehicle-detector-endpoint-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>         <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#4711\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4711</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/10/25 15:21:28]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name vehicle-detector-endpoint-\u001b[1;36m10\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m25\u001b[0m         \u001b]8;id=830817;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=183033;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#4711\u001b\\\u001b[2m4711\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "# Deploy the model\n",
    "predictor = img_classifier_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    endpoint_name='vehicle-detector-endpoint-10-04-25', # ensure to give unique name\n",
    "    data_capture_config=data_capture_config,\n",
    "    wait=True  # waits for deployment to finish\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c43d88-fe60-41ec-84dd-7613a24f75ba",
   "metadata": {},
   "source": [
    "## Test inference through endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59802a3-f916-4861-a316-e36839b134ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b2ac63-31fb-4b65-8025-6c29af5faff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383ed5ae-7aff-4753-a506-dcb09c0af264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45078376-97f4-4333-87f4-4190b6d3149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "predictor = Predictor(endpoint_name=endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fdb49ed4-a7b3-4e98-98c6-0ecee915bd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialise image for inference\n",
    "predictor.serializer = IdentitySerializer(\"image/png\")\n",
    "with open(\"../Data/test/bike_s_000694.png\", \"rb\") as f:\n",
    "    payload = f.read()\n",
    "\n",
    "    \n",
    "inference = predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ca94d8e1-2b44-4894-8d61-9e3e6b111761",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = inference.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "76bad179-b4c1-4acb-8a91-da0fd16425f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0.9389722347259521, 0.0002591302036307752, 0.0033516166731715202, 5.067536676506279e-06, 0.05736708268523216, 4.493407323025167e-05]'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "54f1cc37-636d-455a-96ae-965a004c2e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# need to convert string into list\n",
    "raw = inference\n",
    "\n",
    "# Convert it to list\n",
    "if isinstance(raw, str):\n",
    "    inference = json.loads(raw)\n",
    "else:\n",
    "    inference = raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "de979eb8-09fc-461c-bc6b-b9de65d1dd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_index = inference.index(max(inference))\n",
    "\n",
    "index_to_vehicle = {\n",
    "0: \"bicycle\",\n",
    "1: \"bus\",\n",
    "2: \"motorcycle\",\n",
    "3: \"pickup_truck\",\n",
    "4: \"tractor\",\n",
    "5: \"tank\"\n",
    "}\n",
    "vehicle = index_to_vehicle[vehicle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6898a494-49d6-468c-89cc-61e7d0245444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bicycle'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(vehicle, max(inference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
